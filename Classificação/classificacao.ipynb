{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação\n",
    "\n",
    "## 1. Regressão Logística\n",
    "- Supervisionada: y = 0 (classe negativa) ou 1 (classe positiva ==> é a que queremos detectar, mais rara)\n",
    "- Paramétrica\n",
    "- Rede neural de uma camada\n",
    "- Feature scaling necessária (gradient descent)\n",
    "\n",
    "Exemplos:\n",
    "- Email: **Spam (1)** x Not-spam (0)\n",
    "- Transações: **Fraude (1)** x Não fraude (0)\n",
    "- Crédito: adimplente (0) x **inadimplente (1)**\n",
    "\n",
    "Por que não Regressão Linear?\n",
    "- Predições > 1 ou < 0 não fazem sentido\n",
    "- Outliers podem afetar o preditor\n",
    "\n",
    "![linear_vs_logistic](img/linear_vs_logistic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Função de predição: Sigmoide\n",
    "Função de predição (modelo) limitada entre 0 e 1:\n",
    "\n",
    "$g(z) = \\frac{1}{1 + e^{-z}}$ com $z = \\theta^Tx$ (sigmoide)\n",
    "\n",
    "Sendo X uma matriz pxn (p: número de parâmetros, n: número de samples) e $\\theta$ um vetor de dimensão p.\n",
    "\n",
    "Uma das vantagens da função sigmoide é que sua derivada é simples de calcular:\n",
    "\n",
    "$s'(z) = s(z)(1 - s(z))$\n",
    "\n",
    "![sigmoide](img/sigmoide.png)\n",
    "\n",
    "$g(z) \\geq 0.5 \\implies z \\geq 0$\n",
    "$g(z) \\leq 0.5 \\implies z \\leq 0$\n",
    "\n",
    "O g(z) é a \"probabilidade de prevermos 1 (a classe positiva). Ou seja, $h_{\\theta}(x) = p(y = 1;x)$.\n",
    "\n",
    "#### Função de custo\n",
    "Não podemos usar a mesma função de custo que a regressão linear, pois isso resultaria em uma função não-convexa. Isso implicaria em vários mínimos locais, de forma que o gradient descent poderia não encontrar o mínimo global.\n",
    "\n",
    "![convex_not_convex](img/convex_not_convex.png)\n",
    "\n",
    "Usaremos então a função Cross-Entropy (Log-Loss):\n",
    "\n",
    "\\begin{equation}\n",
    "cost(h_{\\theta}(x), y) =  \n",
    "\\begin{cases} \n",
    "-log(h_{\\theta}(x))  , &y = 1\\\\\n",
    "-log(1 - h_{\\theta}(x))  , &y = 0\\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Ou de outra forma:\n",
    "\n",
    "$cost(h_{\\theta}(x), y) = -ylog(h_{\\theta}(x)) - (1-y)log(1 - h_{\\theta}(x))$\n",
    "\n",
    "![cost_logistic](img/cost_logistic.png)\n",
    "\n",
    "Quando y=1, queremos penalizar predições próximas de 0\n",
    "\n",
    "Quando y=0, queremos penalizar predições próximas de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gradient Descent\n",
    "repeat {\n",
    "\n",
    "$\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "} (simultaneously update $\\theta_j$ for $j=0, 1, ..., n$)\n",
    "\n",
    "A derivada da função Log-Loss é proporcional à diferença entre a predição e o valor real (h(x)-y). Se a predição é boa, a diferença é pequena, e portanto a derivada é pequena (estamos nos aproximando do mínimo).\n",
    "\n",
    "#### Decision Boundary\n",
    "$H_{\\theta}(x) \\geq 0.5 \\implies \\theta^Tx \\geq 0 \\implies predict : 1$\n",
    "\n",
    "$H_{\\theta}(x) \\leq 0.5 \\implies \\theta^Tx \\leq 0 \\implies predict : 0$\n",
    "\n",
    "Decision boundary: $\\theta^Tx = 0$ (pois nosso threshold está em 0.5)\n",
    "\n",
    "![decision_boundary](img/decision_boundary.png)\n",
    "\n",
    "Se **diminuímos o threshold** (exemplo: threshold = 0.25), então o intervalo em que prevemos 1 é maior. Logo somos **menos exigentes** na nossa predição.\n",
    "\n",
    "Se **aumentamos o threshold** (exemplo: threshold = 0.75), então o intervalo em que prevemos 1 é menor. Logo somos **mais exigentes** na nossa predição.\n",
    "\n",
    "#### Interpretação dos coeficientes\n",
    "Logit:\n",
    "\n",
    "$ln\\frac{p(1|X)}{1 - p(1|X)} = b_0 + b_1x_1 + ... + b_jx_j$\n",
    "\n",
    "Aumentar X de uma unidade altera as log odds de $\\beta_1$, ou seja, multiplica as odds por $e^{-\\beta_1$.\n",
    "\n",
    "A quantidade que p(x) muda por conta de uma mudança de uma unidade em X depende do valor atual de X.\n",
    "\n",
    "Obs: Odds = $\\frac{p(x)}{1 - p(x)}$\n",
    "\n",
    "A **probabilidade** de um evento acontecer é a **fração de vezes** que você espera ver aquele evento em várias tentativas.\n",
    "\n",
    "As **chances (odds)** são definidas como sendo a **fração entre a probabilidade do evento ocorrido pela probabilidade do evento não ocorrer.**\n",
    "\n",
    "Ex: Se um cavalo de corrida ganha 25 vezes durante 100 corridas, e perde nas 75 restantes, a probabilidade dele ganhar é 0.25, e as chances dele ganhar são 25/75 = 0.333...\n",
    "\n",
    "#### Determinação dos coeficientes\n",
    "A determinação dos coeficientes é feita através do método do Gradient Descent.\n",
    "\n",
    "Max Verossimilhança: a gente consegue descobrir o formato do custo que tenta maximizar as probabilidades dos exemplos\n",
    "\n",
    "A ideia é maximizar a função a seguir:\n",
    "\n",
    "$l(\\beta_0, \\beta_1) = \\prod_{i: y_i = 1}p(x_i)\\prod_{i': y_{i'} = 0}p(x_{i'})$\n",
    "\n",
    "Podemos ver que nos casos onde a probabilidade calculada é próxima do valor real de y, a função de verossimilhança é maximizada.\n",
    "\n",
    "#### Regularização\n",
    "\n",
    "Na regressão logistica, também podemos nos de parar com problemas de overfitting. Para contornar esse problema podemos aplicar técnicas de regularização.\n",
    "\n",
    "![overfit_logistic](img/overfit_logistic.png)\n",
    "\n",
    "A função de custo é atualizada da seguinte forma:\n",
    "\n",
    "FALTA UMA IMAGEM AQUI\n",
    "\n",
    "#### Classificação multiclasse\n",
    "Problemas em que y pode assumir mais de dois valores\n",
    "\n",
    "Ex.: temperatura (y = {ensolarado, chuvoso, nublado), classificar animal em uma imagem (y = {cachorro, gato, peixe, ...})\n",
    "\n",
    "![multiclass](img/multiclass.jpeg)\n",
    "\n",
    "**One Vs All**\n",
    "\n",
    "![one_vs_all](img/one_vs_all.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes\n",
    "\n",
    "- Supervisionado\n",
    "- Paramétrico\n",
    "- Uma coleção de algoritmos (classificadores de Naive Bayes)\n",
    "- Não precisa de feature scaling\n",
    "- Baseia-se no Teorema de Bayes:\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$ ou $posterior = \\frac{likelihood * prior}{evidence}$\n",
    "\n",
    "Assume que:\n",
    "- Cada par de features é **independente** (o que raramente é válido...)\n",
    "\n",
    "Modelo da probabilidade de y, dado um dataset X:\n",
    "$P(y|X) = \\frac{P(X|y)P(y)}{P(X)}\n",
    "\n",
    "Como assumimos que as features são independentes, temos que $P(x_i,x_j) = P(x_i)P(x_j)$. Portanto:\n",
    "\n",
    "$P(y|x_1, ..., x_n) = \\frac{P(x_1|y)P(x_2|y)...P(x_n|y)P(y)}{P(x_1)P(x_2)...P(x_n)}$\n",
    "\n",
    "O denominador é constante, portanto podemos ignorá-lo:\n",
    "\n",
    "$P(y|x_1, ..., x_n) \\propto P(y)\\prod_{i=1}^nP(x_i|y)$\n",
    "\n",
    "O classificador pode ser escrito como:\n",
    "\n",
    "$\\hat{y} = argmax_{k \\in {1,...,K}} p(C_k)\\prod_{i=1}^n p(x_i|C_k)$\n",
    "\n",
    "O valor calculado é **proporcional às probabilidades** (Nosso dataset pode não ser representativo)\n",
    "\n",
    "Nós **estimamos** as curvas de probabilidade!!! Logo, **não são realmente probabilidades**. São **likelihoods**. Existe uma chance de o valor estimado de probabilidade pelo modelo não ser o valor real da probabilidade.\n",
    "\n",
    "Ex: Detector de spams\n",
    "\n",
    "Em um conjunto de 100 emails, 25 deles são spam.\n",
    "\n",
    "|  | Buy| Cheap | Buy + Cheap |\n",
    "| --- | --- | --- | --- |\n",
    "| Spam | 20 | 15 | 12|\n",
    "| Não-Spam | 5 | 10 | 0 |\n",
    "\n",
    "Se um email tem as palavras Buy e Cheap, é spam ou não spam?\n",
    "P(S|\"Buy\"+\"Cheap) P(S) P(\"Buy\"|S) P[\"Cheap\"|S) = 25/100 * 20/25 * 15/25 = 0.12\n",
    "\n",
    "P(NS|\"Buy\"+\"Cheap) P(NS) * P(\"Buy\"| NS) P(\"Cheap\" |NS) = 75/100 * 5/75 * 10/75 = 0.0067\n",
    "\n",
    "Como P(S|\"Buy\"+\"Cheap) > P(NS|\"Buy\"+\"Cheap) -> é spam\n",
    "\n",
    "Ex:\n",
    "\n",
    "y = {sim, não) ==> jogar golf hoje\n",
    "\n",
    "x1 = {sol, encoberto, chuva) ==> clima\n",
    "\n",
    "x2 = {calor, médio, frio) ==> temperatura\n",
    "\n",
    "![outlook_temp](img/outlook_temp.png)\n",
    "\n",
    "Pra cada valor de variável x1 e xj, estimamos $p(x_i|y_j)$, pra cada $i$ e $j$, construindo a tabela anterior, a partir das ocorrências das variáveis no dataset.\n",
    "\n",
    "Para estimarmos a probabilidade de irmos jogar golf dado que hoje está (X=(sol, calor)):\n",
    "\n",
    "$p(y = Sim | X) \\propto p(x_1 = sol| y = Sim) * p(x_2 = calor | y = Sim) * p(y = Sim)$\n",
    "\n",
    "$p(y = Não | X) \\propto p(x_1 = sol| y = Não) * p(x_2 = calor | y = Não) * p(y = Não)$\n",
    "\n",
    "Vemos qual é maior e decidimos.\n",
    "\n",
    "### Multinomial\n",
    "\n",
    "As variáveis preditoras são valores discretos que correspondem à frequência de ocorrência de cada um dos eventos\n",
    "\n",
    "$X = (x_1, x_2, ..., x_n)$, com cada $x_i$ sendo ocorrências do evento $i$\n",
    "\n",
    "$p = (p_1, p_2, ..., p_n)$ são as probabilidades estimadas de cada evento, com base no dataset\n",
    "\n",
    "Likelihood de observarmos um dado X:\n",
    "\n",
    "$p(x|C_k) = \\frac{(\\sum_i x_i)!}{\\prod_i x_i!}\\prod_i p_{ki}^{x_i}$\n",
    "\n",
    "Usado para Bag of Words: cada $x_i$ é a qtde de uma palavra no texto. Queremos estimar a probabilidade de o texto pertence a alguma classe $y_j$.\n",
    "\n",
    "OBS: Bernouilli-caso particular do multinomial, onde as features são valores booleanos (binários).\n",
    "\n",
    "### Gaussiano\n",
    "As variáveis preditoras são valores continuos, e **assumimos** que elas provêm de uma distribuição Gaussiana.\n",
    "\n",
    "\n",
    "$p(x=v|C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}}e^{-\\frac{(v-\\mu_k)^2}{2\\sigma_k^2}}$\n",
    "\n",
    "Se algum $x_i$ não é normal, podemos aplicar o método KDE (Kernel Density Distribution): A ideia é convoluir uma Kernel distribution que tente normalizar a estimativa de probabilidades $f(x_i)$.\n",
    "\n",
    "Observações:\n",
    "- E se X teste for muito grande? (algumas probs serão bem pequenas)\n",
    "    - Tirar o log pode resolver o problema do underflow\n",
    "- O classificador Bayesiano é ótimo (matematicamente)\n",
    "    - Mas a hipótese de independência + não representatividade da amostra X em relação à população ==> na realidade não é ótimo.\n",
    "- Não deveria funcionar, pois as vars devem ter uma correlação (parece uma hipótese\n",
    "fraca), mas na prática, empiricamente, vemos que o algoritmo funciona bem!\n",
    "    - O Naive Baves raramente consegue estimar bem a probabilidade correta das classes, mas isso não costuma ser necessário para muitas aplicações. O importante é saber qual classe tem maior probabilidade, e isso ele consegue fazer relativamente bem.\n",
    "- Zero frequency: valor de um $x_i$ (categórico) que não ocorre nunca no train, mas ocorre no teste, terá probabilidade estimada O pelo modelo.\n",
    "    - Alternativa: pode-se atribuir 1 no início para o count desses valores de $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KNN pra classificação\n",
    "- Supervisionado\n",
    "- Não paramétrico\n",
    "- Preguiçoso → Funciona a partir do cálculo de distâncias (ao dar fit, ele carrega todos os dados na memória) → Se o dataset for mto grande ele vai demorar mais \n",
    "- Precisa de feature scaling (Normalizações)\n",
    "\n",
    "![\"feature_scaling\"](img/feature_scaling.png)\n",
    "\n",
    "- Curse of dimensionality\n",
    "    - Quando temos muitas dimensões (acima de 10~16), as distâncias entre pontos se tornam praticamente equidistantes.\n",
    "\n",
    "O KNN busca estimar a distribuição condicional de Y dado X, e então classificar uma determinada observação para a classe com maior probabilidade **estimada**. A probabilidade da classe j dado X é dada pela fração de pontos no espaço cujo valor de\n",
    "resposta é j:\n",
    "\n",
    "$P_r(Y=j|X=x_0) = \\frac{1}{K}\\sum_{i \\in N_0}I(y_i=j)$\n",
    "\n",
    "Treino: Somente escolher os pontos que vão fazer parte do espaço.\n",
    "\n",
    "Teste: Usar os pontos anteriores pra fazer a votação (encontrar a classe mais frequente). Atribuímos essa classe ao novo exemplo,\n",
    "\n",
    "### 3.1 Algoritmo\n",
    "O sample é classificado por um voto majoritário de seus K vizinhos.\n",
    "\n",
    "### 3.2 Escolha do k\n",
    "K pequeno: Decision Boundary muuuito flexível (overfit)\n",
    "\n",
    "K grande: Decision Boudary inflexível, usando muitos pontos do dataset pra cada cálculo de média (underfit)\n",
    "\n",
    "![knn_1_100](img/knn_1_100.jpg)\n",
    "\n",
    "Problema binário (duas classes) e valor de K par.\n",
    "\n",
    "E empates, como ele resolve?\n",
    "- Desempate com pesos da distância\n",
    "- Desempate aleatório\n",
    "\n",
    "Se o número de classes é impar (3, por exemplo) e K par (K = 4, por exemplo), não ocorrerão tantos empates.\n",
    "\n",
    "É interessante utilizar K ímpar.\n",
    "\n",
    "\n",
    "### 3.3 Lazy Algorithm\n",
    "- Não constroem descrições gerais e explícitas (função alvo) a partir dos exemplos de treinamento;\n",
    "- Generalização é adiada até o momento da classificação;\n",
    "- Armazena-se uma base de exemplos instances) que é usada para realizar a classificação de uma nova query (exemplo não visto);\n",
    "- Em muitos casos apresenta um alto custo computacional (por conta do cálculo de distâncias).\n",
    "\n",
    "### 3.4 Como lidar com atributos nominais?\n",
    "Mudar a função de distância-e.g., usando coeficiente de casamento simples (simple matching):\n",
    "\n",
    "$d_{SM}(x,y) = \\sum_{i=1}^n s_i$\n",
    "\n",
    "Onde $s_i$ é tal que $(x_i = y_i) \\implies s_i = 0$ e $(x_i \\neq y_i) \\implies s_i = 1$\n",
    "\n",
    "$f(x_q) = argmax_{v \\in V} \\sum_{i=1}^k w_i \\delta(x, f(x_i))$ \n",
    "\n",
    "Onde $\\delta(a,b)$ é tal que $(a = b) \\implies \\delta(a,b) = 1$ e $(a \\neq b) \\implies \\delta(a,b) = 0$\n",
    "\n",
    "![knn_nominal](img/knn_nominal.png)\n",
    "\n",
    "(Hipótese) Usa vars continuas para decidir os k mais próximos, em seguida, verifica nesses k exemplos quantos (count) têm um valor de X K != do próprio valor. Com isso, simula-se uma distância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Árvores de Classificação\n",
    "- Árvore de Classificação\n",
    "- Supervisionado\n",
    "- Não paramétrico\n",
    "- Não precisa de feature scaling\n",
    "\n",
    "**Vantagens**:\n",
    "- Fácil de compreender/visualizar\n",
    "\n",
    "**Desvantagens**:\n",
    "- Possibilidade de overfitting\n",
    "\n",
    "**Como fazer previsões?**\n",
    "\n",
    "\"Descer\" na árvore até o no correspondente. A saída prevista será a classe que ocorre mais naquela folha.\n",
    "\n",
    "### 4.1 Gini\n",
    "(== impureza de uma região (falta de preponderância de uma classe na região))\n",
    "\n",
    "Para cada classe,\n",
    "\n",
    "$G = \\sum_{k=1}^K \\hat{p_{mk}}(1 - \\hat{p_{mk}})$\n",
    "\n",
    "Outra forma de escrever\n",
    "\n",
    "$G = 1 - \\sum_{k=1}^K \\hat{p_{mk}}^2$\n",
    "\n",
    "Exemplos:\n",
    "- 1-(0.5^2-(0.5)^2 = 0.5\n",
    "- 1-(0.2)^2-(0.8)^2 = 0.32\n",
    "- 1 - (0.05)^2 - 10.95)^2 = 0.095 (a folha tem muitos exemolos de uma classe, a divisão foi muito boa)\n",
    "- 1-(1.0)^2-(0.0)^2 = 0 (divisão perfeita)\n",
    "\n",
    "### 4.2 Cross-Entropy\n",
    "Uma alternativa ao Gini é a cross-entropy\n",
    "\n",
    "$D = -\\sum_{k=1}^K \\hat{p_{mk}}log(\\hat{p_{mk}})$\n",
    "\n",
    "($\\approx 0$ se $p \\approx 1$ ou $p \\approx 0$, como no Gini)\n",
    "\n",
    "### 4.3 Construção da árvore\n",
    "1. Calcular a entropia (ou impureza) da variável target\n",
    "\n",
    "2. O dataset é dividido a partir dos diferentes atributos.\n",
    "\n",
    "    a. A entropia para cada ramo é calculada\n",
    "    \n",
    "    b. Calcula-se a entropia total da divisão (split) a partir de uma média ponderada das entropias de cada ramo.\n",
    "\n",
    "    c. Calcula-se o **Ganho de Informação = entropia antes da divisão - entropia da divisão**\n",
    "    \n",
    "3. Escolher o atributo com maior Ganho de Informação para ser o nó de decisão. Dividir o dataset em dois ramos a partir desse nó.\n",
    "\n",
    "4. Repetir o processo em cada Ramo\n",
    "\n",
    "- Pre poda: gtde de exemplos max por folha, etc.\n",
    "- Pós poda: constrói a árvore e vai cortando ramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bagging, Boosting, Random Forest\n",
    "\n",
    "Melhoram a predição, mas reduzem a interpretabilidade:\n",
    "\n",
    "![ensemble_learning](img/ensemble_learning.png)\n",
    "\n",
    "### 5.1 Bagging (é um método geral) - Boostrae AGgregation\n",
    "Árvores são \"building blocks\".\n",
    "\n",
    "Treinamos B árvores de regressão, usando B bootstrapped training sets. Fazemos a média das predições das B árvores.\n",
    "\n",
    "(Bootstrapped sample: amostra tirada aleatoriamente do dataset original)\n",
    "\n",
    "$\\hat{f}_{bag}(x) = \\frac{1}{B}\\sum_{b=1}^B\\hat{f}^{*b}(x)$\n",
    "\n",
    "As árvores intermediárias não são podadas.\n",
    "\n",
    "Ideia: reduzir a variância! Propriedade: $Var(\\bar{x}) = \\frac{\\sigma^2}{n}$\n",
    "\n",
    "#### Out of Bag Error\n",
    "Quando realizamos o Bootstrap, em torno de 1/3 dos dados não são selecionados. Esses dados compõem o Out-of-Bag dataset, que pode ser utilizado para validar o nosso modelo. Assim, aplicamos o modelo no Out-of-Bag dataset, e a proporção de observações que forem incorretamente classificadas definirão o **Out-of-Bag Error**.\n",
    "\n",
    "\n",
    "#### Feature importance\n",
    "Somar o quanto que o Gini Index diminui a cada divisão em relação a uma feature, e fazer a média de todas as árvores B. Com isso, conseguimos determinar as features mais importantes.\n",
    "\n",
    "### 5.2 Random Forest\n",
    "- Bagged Tree melhorado\n",
    "- Estratégia para descorrelacionar as árvores\n",
    "\n",
    "Treinamos B árvores de regressão, usando B bootstrapped training sets. Fazemos a média das predições das B árvores.\n",
    "\n",
    "A diferença é que, sempre que formos fazer um split na construção de uma árvore, vamos **escolher aleatoriamente $m \\leq \\sqrt{p}$ preditores de todos os $p$ preditores do modelo**.\n",
    "\n",
    "Então, usamos esses $m$ preditores para calcular o melhor corte.\n",
    "\n",
    "Ideia: Preditores importantes ficam no topo da maioria das árvores, no bagging. Assim, evitamos isso na RF, e descorrelacionamos as árvores.\n",
    "\n",
    "B pode ser tão grande quanto quisermos, não dá overfitting (RF, Bagging).\n",
    "\n",
    "\n",
    "#### Algoritmo\n",
    "Considere que temos N exemplos de treinamento\n",
    "\n",
    "Para cada uma das t iterações faça:\n",
    "\n",
    "1. Amostrar N exemplos com reposição (bagging).\n",
    "\n",
    "2. Induzir uma árvore repetindo recursivamente os seguintes passos em cada novo nó da árvore, até que o critério de parada seja satisfeito:\n",
    "\n",
    "    a. Selecionar m atributos (e.g., $m \\leq \\sqrt{p}$) aleatoriamente.\n",
    "\n",
    "    b. Selecionar o melhor atributo/corte (entre os m candidatos).\n",
    "\n",
    "    c. Criar dois nós filhos usando o ponto de corte do passo anterior.\n",
    "3. Armazenar a árvore obtida.\n",
    "\n",
    "Para cada uma das t árvores classificação:\n",
    "1. Predizer o rótulo de classe do exemplo do conjunto-alvo.\n",
    "\n",
    "2. Retornar a classe predita com maior frequência.\n",
    "\n",
    "#### Parámetros Sklearn\n",
    "- n estimators (B): número de árvores na floresta\n",
    "    - Quanto mais árvores, menor a probabilidade de dar overfit\n",
    "    - N estimators = 1 equivale a uma árvore de classificação\n",
    "    -Ex: 100, 200,500...\n",
    "- max depth: máxima profundidade das árvores\n",
    "    - Quanto menor, mais simples serão as árvores, diminuindo o overfit\n",
    "    - Ex: 5,10,20...\n",
    "- min samples leaf: número mínimo de exemplos para ser considerado uma folha\n",
    "    - Ex: 1,2,4..\n",
    "- max features (m): número de features para considerar quando estiver procurando a melhor divisão\n",
    "    - O mais comum é $m = \\sqrt{p}\n",
    "    - Quanto menor, menor a probabilidade de dar overfit (mas se for muito pequeno pode dar underfit)\n",
    "    - Ex: 'auto', 'sgrt', 'log2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Boosting\n",
    "\n",
    "- Combina varios “weak learners” em sequência\n",
    "\n",
    "- Alguns desses modelos não são paralelizáveis\n",
    "\n",
    "- Cada modelo subsequente tenta “corrigir” os erros dos predecessores\n",
    "\n",
    "- Ensemble é baseado no voto ponderado (acurácia) dos componentes\n",
    "\n",
    "$\\hat{f}(x) = \\sum_{b=1}^B \\hat{f}^{b}(x)$\n",
    "\n",
    "- Não usar modelos complexos para os “weak learners”, pode dar overfitting (limitar a altura das árvores).\n",
    "\n",
    "- Podem overfittar pro ruido presente nos dados (há modelos de boosting que resolvem overfitting, como LPBoost, QPBoost).\n",
    "\n",
    "\n",
    "#### 5.3.1 Adaboost\n",
    "- “Weak learners” = stumps (árvores com um nó e duas folhas)\n",
    "- Cada stump tem um “Amount of say” na hora da classificação\n",
    "\n",
    "1. Atribuir um peso a cada observação, indicando o quão importante é acertar a previsão para aquela observação. Inicialmente, todo os pesos são inicializados com $\\frac{1}{n}$, onde $n$ é o número de observações\n",
    "\n",
    "2. Criar o primeiro stump da floresta (achando a variável que faz o melhor trabalho classificando os exemplos)\n",
    "\n",
    "3. Calculamos o Amount of Say que o stump terá:\n",
    "$A = \\frac{1}{2}log(\\frac{1 - TE}{TE})$, onde $TE$ = Total error = soma dos erros associados com os exemplos incorretamente classificados.\n",
    "\n",
    "Quando um stump é bom, e o TE é pequeno, o Amount of Say é alto\n",
    "\n",
    "Quando um stump é mediano, o Amount of Say é 0 (feature selection)\n",
    "\n",
    "Quando um stump é ruim, e o TE é grande, o Amount of Say é baixo\n",
    "\n",
    "4. Atualizar os pesos de todas as observações\n",
    "\n",
    "Observações incorretamente classificadas: $SW = SW*e^{A}$\n",
    "\n",
    "Observações corretamente classificadas: $SW = SW*e^{-A}$\n",
    "\n",
    "Atualizar os pesos para que eles somem 1.\n",
    "\n",
    "5. Criamos um dataset escolhendo as observações de acordo com sua probabilidade (peso) para que as observações com maior peso sejam escolhidos mais vezes.. \n",
    "\n",
    "6. Repetir o processo\n",
    "\n",
    "**Como fazer previsões?**\n",
    "\n",
    "Usamos os stumps para fazer as predições, e escolhe a saída de acordo com o Amount of Say dos stumps.\n",
    "\n",
    "#### 5.3.2 Gradient Boosting\n",
    "\n",
    "- Treina cada preditor com os erros residuais feitos pelo preditor anterior.\n",
    "- O modelo usa o erro residual como target no treino; essa target é atualizada a cada modelo.\n",
    "- A ideia é que dar vários passos na direção correta resulta em melhores predições\n",
    "\n",
    "Para treinar o modelo $m+1$, fazemos: $F_{m+1}(x) = F_m(x) + h_m(x)$\n",
    "\n",
    "Tomamos o erro cometido é $L_{MSE} = \\frac{1}{2}\\sum_{i = 1}^n (y_i - F_m(x_i))^2$\n",
    "\n",
    "Em que $h_m(x)= -\\frac{\\partial L_{MSE}}{\\partial F} = \\sum_{i = 1}^n (y_i - F_m(x_i))$\n",
    "\n",
    "Ou seja, o cálculo do próximo preditor é uma combinação entre o preditor atual mais um termo que representa o erro residual.\n",
    "\n",
    "OBS: Os residuais são o gradiente do MSE. Mais genericamente, o pseudo-residual é o gradiente da função de custo. \n",
    "\n",
    "![gradient-boosting](img/gradient-boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Redes Neurais\n",
    "- Supervisionado\n",
    "- Baixa interpretabilidade (black-box)\n",
    "- Não linear\n",
    "- Data hunger (precisa de muitos dados pra funcionar bem)\n",
    "    - Dados não tabulares\n",
    "    - NLP\n",
    "    - Audio\n",
    "    - Imagens\n",
    "- Modelo antigo, cuja ideia só pôde ser implementada ~nos anos 2000 com o aumento da quantidade de dados e de processamento aumentaram.\n",
    "\n",
    "Discussão/Motivação: Simular o funcionamentos dos neurônios, mas na prática, não tem um funcionamento igual (não se conhece o cérebro completamente).\n",
    "\n",
    "Consegue aprender features automaticamente, utilizando hidden layers.\n",
    "\n",
    "### 6.1 Perceptron\n",
    "\n",
    "É uma rede neural simples, com uma input layer, e uma output layer com uma saida.\n",
    "\n",
    "Entradas: $x_0$, $x_1$, ... , $x_n$, onde $x_0$ é o bias\n",
    "\n",
    "Pesos: $w_0, w_1, …, w_n$\n",
    "\n",
    "![perceptron](img/perceptron.png)\n",
    "\n",
    "**O bias term serve para permitir que a curva não seja sempre caindo em $0$ se $x_i = 0$ para todo $x$. O mesmo argumento se aplica para outros modelos, como na Regressão Linear, que tem um termo $\\theta_0$ que é o bias. O fit do bias term permite fazer um fit melhor, deslocando a curva mais livremente para se ajustar aos dados de treino.**\n",
    "\n",
    "O perceptron calcula a saída a partir da média ponderada das entradas $x_i$:\n",
    "\n",
    "$y= \\left \\{ \\begin{matrix} \n",
    "0, & \\mbox{se } \\sum_iw_ix_i + b \\leq 0 \\\\ \n",
    "1, & \\mbox{se } \\sum_iw_ix_i + b \\gt 0 \n",
    "\\end{matrix} \\right.$\n",
    "\n",
    "Um perceptron pode ser visto como um neurônio artificial cuja função de ativação é a função de Heaviside (step)\n",
    "\n",
    "#### O problema do XOR\n",
    "\n",
    "O problema da arquitetura simplificada do perceptron é que ele não consegue resolver problemas não linearmente separáveis.\n",
    "\n",
    "O exemplo mais comum é o de modelar a função lógica XOR:\n",
    "\n",
    "\n",
    "| A| B | S |\n",
    "| --- | --- | --- |\n",
    "|  0  |  0  |  0  |\n",
    "|  0  |  1  |  1  |\n",
    "|  1  |  0  |  1  |\n",
    "|  1  |  1  |  0  |\n",
    "\n",
    "![xor](img/xor.png)\n",
    "\n",
    "Notar que não é possível separar os pontos com saída 1 (verdes) dos pontos de saída 0 (vermelhos) com uma reta. Logo, o \n",
    "perceptron não é capaz de resolver esse problema, pois só consegue criar uma decision boundary linear.\n",
    "\n",
    "Poderemos resolver isso adicionando layers entre a input layer e a output layer, que chamamos de **hidden layers**.\n",
    "\n",
    "\n",
    "\n",
    "#### Perceptron x Sigmoid Neuron\n",
    "A função de ativação usada pelo Perceptron é muito rígida, uma vez que uma pequena mudança na entrada pode causar uma mudança muito radical na saída. \n",
    "\n",
    "Exemplo: Uma rede neural para decidir se vamos ou não ver um filme. A única feature é $x_1$ = avaliação dos críticos, com $w_1 = 1$, e temos $bias = w_0 = -0.5$. Logo: $y = x_1 - 0.5$.\n",
    "\n",
    "- Se um filme tem nota $x_1 = 0.51$: $y = 0.1 > 0$ (assistimos o filme).\n",
    "- Se um filme tem nota $x_1 = 0.49$: $y = -0.1 < 0$ (não assistimos o filme).\n",
    "\n",
    "\n",
    "![heaviside](img/heaviside.png)\n",
    "\n",
    "Uma solução para isso é a utilização de uma função de ativação sigmoide, que é mais suave que o step de Heaviside. A saída passa a ser um real, e não mais um valor binário, podendo ser interpretada como a probabilidade de que y = 1.\n",
    "\n",
    "![sigmoid_neuron](img/sigmoid_neuron.png)\n",
    "\n",
    "\n",
    "### 6.2 Rede Neural\n",
    "\n",
    "![neural_network](img/neural_network.png)\n",
    "\n",
    "#### Forward propagation\n",
    "\n",
    "Nesta etapa, calculamos os valores de $a^{[l]}$ de cada unidade.\n",
    "\n",
    "Para isso, inicializamos os $\\Theta^{[l]}$ com valores aleatorios entre $[-\\epsilon, +\\epsilon]$, e entramos com as features $x_i$ na input layer.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "$a^{(1)} = x$\n",
    "\n",
    "$z^{(2)} = \\Theta^{(1)}a^{(1)}$\n",
    "\n",
    "$a^{(2)} = g(z^{(2)})$ (add bias $a_0^{(2)}$)\n",
    "\n",
    "$z^{(3)} = \\Theta^{(2)}a^{(2)}$\n",
    "\n",
    "$a^{(3)} = g(z^{(3)})$ (add bias $a_0^{(3)}$)\n",
    "\n",
    "$z^{(4)} = \\Theta^{(3)}a^{(3)}$\n",
    "\n",
    "$a^{(4)} = g(z^{(4)}) = h_{\\Theta}(x)$ \n",
    "\n",
    "\n",
    "Na output layer, obtemos um $a^{[L]}$, com $L$ correspondendo à última camada da rede neural.\n",
    "\n",
    "Em seguida, para corrigir o valor dos pesos $W$, fazemos o backward propagation.\n",
    "\n",
    "#### Backward propagation\n",
    "\n",
    "O objetivo é calcular as os $\\delta^{[l]}$’s de cada neurônio a partir do valor de $a^{[l]}$ calculados no Forward propagation e do target $y_i$. Começamos do final, onde utilizamos $\\delta^{[L]} = a^{[L]} - y_i$.\n",
    "\n",
    "A importância de se calcular os $\\delta$’s, é que podemos escrever as derivadas da função de custo em relação aos parâmetros da rede: $\\frac{\\partial }{\\partial \\Theta_{i,j}^{(l)}} J(\\Theta) = a_j^{(l)}\\delta_i^{(l+1)}$. Utilizamos esses derivativos mais a função $J(\\Theta)$ para otimizar $J(\\Theta)$ em relação a todos os parâmetros $\\Theta_{i,j}$, utilizando um método de otimização.\n",
    "\n",
    "Dado um training se $(x^{(1)}, y^{(1)}) ... (x^{(m)}, y^{(m)})$.\n",
    "\n",
    "Setamos $\\Delta^{(l)}_{i,j} = 0$ para $(l,i,j)$, (temos uma matriz cheia de zeros)\n",
    "\n",
    "Para cada observação $t = 1$ até $m$:\n",
    "1. Setamos $a^{(1)} := x^{(t)}$\n",
    "\n",
    "2. Realizamos a forward propagation para calcular $a^{(l)}$ for $l=2,3,…,L$\n",
    "\n",
    "3. Usando $y^{(t)}$, computamos $\\delta^{(L)} = a^{(L)} - y^{(t)}$\n",
    "\n",
    "4. Computamos $\\delta^{(L-1)}, \\delta^{(L-2)},...,\\delta^{(2)}$ using $\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\ .*\\ a^{(l)}\\ .*\\ (1 - a^{(l)})$\n",
    "\n",
    "5. $\\Delta_{i,j}^{(l)}= \\Delta_{i,j}^{(l)} + a_j^{(l)}\\delta_i^{(l+1)}$ ou de forma vetorizada, $\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T$\n",
    "\n",
    "Função de custo com regularização (para classificação):\n",
    "\n",
    "$J(\\Theta) = -\\frac{1}{m}[\\sum_{i=1}^m\\sum_{k=1}^K y_k^{(i)}log(h_{\\Theta}(x^{(i)}))_k + (1-y_k^{(i)})log(1 - (h_{\\Theta}(x^{(i)}))_k))] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}} (\\Theta_{j,i}^{(l)})^2$\n",
    "\n",
    "Gradient Descent:\n",
    "\n",
    "$\\Theta_{ij}^{(l)} := \\Theta_{ij}^{(l)} - \\alpha\\frac{\\partial}{\\partial\\Theta_{ij}^{(l)}}J(\\Theta)$\n",
    "\n",
    "$D_{ij}^{(l)} := \\frac{1}{m}\\Delta_{ij}^{(l)}$\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\Theta_{ij}^{(l)}}J(\\Theta) = D_{ij}^{(l)}$\n",
    "\n",
    "\n",
    "**Problema:**\n",
    "- **Vanishing gradients:** algumas funções de ativação, como a sigmoide e a tanh, têm a característica de variarem pouco nos extremos, quando $z \\to +\\infty$ ou  $z \\to -\\infty$. Nesse caso, os derivativos calculados a partir dos $\\delta$’s podem ficar pequenos conforme nos aproximamos das camadas iniciais ao fazer o Backward propagation. Isso implica em uma otimização mais lenta.\n",
    "\n",
    "\n",
    "![train_nn](img/train_nn.png)\n",
    "\n",
    "#### Escolha da função de ativação\n",
    "\n",
    "- Sigmoide: $g(z) = \\frac{1}{1+e^{-z}}$\n",
    "- Tangente: $g(z) = tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$\n",
    "    - Quase sempre funciona melhor que a sigmoide pois os outputs ficam entre -1 e 1, então a saída deles têm uma média mais próxima de 0\n",
    "- ReLu: $g(z) = max(0,z)$\n",
    "    - Mais utilizada \n",
    "    - **Contorna o problema dos vanishing gradients**\n",
    "- Leaky ReLu: $g(z) = \\left \\{ \\begin{matrix} z, & \\mbox{if } z > 0 \\\\ 0.01z, & \\mbox{otherwise }  \\end{matrix} \\right.$\n",
    "    - Resolve o “Dying ReLU problem” \n",
    "\n",
    "OBS: No caso de um problema de regressão, a função de ativação da output layer é linear.\n",
    "\n",
    "Neste caso, o custo também muda.\n",
    "\n",
    "#### Escolha de hiperparâmetros\n",
    "- Hidden units (por camada):\n",
    "    - De modo geral, quanto mais, melhor\n",
    "    - Um bom número = algo próximo do número de inputs\n",
    "    - Padrão = 1 hidden layer. Se tiver mais de uma, usar o mesmo número de hidden units por hidden layer\n",
    "- Learning rate\n",
    "- Número de iteração\n",
    "- Número de hidden layers\n",
    "- Escolha das funções de ativação\n",
    "\n",
    "Observação: Para problemas com $n$ classes difrerentes, basta adicionar uma output layer que tenha $n$ unidades, cada uma correspondente à saída desejada. Nesse caso, os outputs $y_i$ devem ter forma vetorial, com 1 na categoria à qual o exemplo pertence: $y = \\begin{bmatrix} 0\n",
    "\\\\ 1\n",
    "\\\\ 0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "#### Early Stopping\n",
    "É uma forma de regularização para evitar overfitting quando treinamos um modelo que usa métodos iterativos, por exemplo gradient descent. \n",
    "\n",
    "A ideia é interromper a otimização antecipadamente para evitar o overfit, quando o erro de validação (generalização) começa a subir. \n",
    "\n",
    "![early_stopping](img/early_stopping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SVM\n",
    "\n",
    "- Supervisionado\n",
    "- Paramétrico\n",
    "\n",
    "### 7.1 Maximum Margin Classifier\n",
    "Assume-se que os exemplos são linearmente separáveis (se não forem, não existe um tal classificador).\n",
    "\n",
    "As features $X_1, X_2, …, X_n$ do problema definem pontos no espaço $n$-dimensional.\n",
    "\n",
    "O maximum margin classifier é um classificador que utiliza um hiperplano, de equação $\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n = 0$ que divide o espaço do problema em duas regiões.\n",
    "\n",
    "**Ideia:**\n",
    "Os exemplos são classificados em uma das duas classes, dependendo se estão localizadas acima do hiperplano, ou abaixo dele:\n",
    "\n",
    "Para um exemplo X:\n",
    "\n",
    "- $\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n > 0$, então está acima do hiperplano. Classificamos $y = +1$.\n",
    "\n",
    "- $\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n < 0$, então está abaixo do hiperplano. Classificamos $y = -1$.\n",
    "\n",
    "O hiperplano é construido de forma a separar todos os dados linearmente, ou seja, $y_i (\\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2} + ... + \\beta_nX_{in}) > 0, \\forall i = 1, …, n.$\n",
    "\n",
    "Neste caso, a decision boundary é sempre linear.\n",
    "\n",
    "Se existir um tal hiperplano, existirão infinitos hiperplanos. Escolher aquele que tem a maior distância mínima das observações de treino pro hiperplano. Essa distância mínima é chamada de **margem** (denotamos por $M$).\n",
    "\n",
    "Os pontos usados para definir a margem são chamados de **support vectors**. O hiperplano e as margens só mudam em função desses pontos, por isso chamamos de “suporte”. Os outros pontos podem ficar em qualquer outra posição acima da margem, que não influenciarão a posição do hiperplano, nem a margem.\n",
    "\n",
    "![maximum_margin_classifier](img/maximum_margin_classifier.png)\n",
    "\n",
    "Formulação:\n",
    "\n",
    "$x_1, …, x_n \\in  R^p$\n",
    "\n",
    "$y_1, …, y_n \\in  \\{-1, 1\\}$\n",
    "\n",
    "O problema de otimização do MMC pode ser escrito como:\n",
    "\n",
    "- Encontrar os parâmetros $\\beta$ e $M$ que maximizam a margem $M$\n",
    "\n",
    "- Sujeito a:\n",
    "    - $\\sum_{j=1}^p\\beta_j^2 = 1$ (a soma de todos os coeficientes do hiperplano deve ser 1).\n",
    "    - $y_i(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + ... + \\beta_px_{ip}) \\geq M, \\forall i = 1,...,n$\n",
    "\n",
    "A condição $\\sum_{j=1}^p\\beta_j^2 = 1$ faz com que $y_i(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + ... + \\beta_px_{ip})$ corresponda à distância entre o ponto e o hiperplano.\n",
    "\n",
    "\n",
    "\n",
    "### 7.2 Support Vector Classifier\n",
    "\n",
    "O Support Vector Classifier também é conhecido como **Soft Margin Classifier**. A margem é considerada “soft” pois pode ser violada por algumas das observações de treino.\n",
    "\n",
    "**Ideia:**\n",
    "Nem todos os problemas são linearmente separáveis, e mesmo os que são, nem sempre o MMC é o classificador mais generalista. Assim, adicionamos outros parâmetros para controlar a flexibilização da margem em relação aos dados de treino: $\\epsilon$’s e $C$. Dessa forma, tentamos classificar bem **a maior parte dos exemplos**.\n",
    "\n",
    "A decision boundary ainda é linear.\n",
    "\n",
    "![support_vector_classifier](img/support_vector_classifier.png)\n",
    "\n",
    "\n",
    "Os **support vectors** são definidos pelos pontos na margem e dentro da margem, pois são os únicos que podem modificar a margem e a posição do hiperplano.\n",
    "\n",
    "O problema de otimização do SVC pode ser escrito como:\n",
    "- Encontrar os parâmetros $\\beta$, $\\epsilon$ e $M$ que maximizam a margem $M$.\n",
    "- Sujeito a:\n",
    "    - $\\sum_{j=1}^p\\beta_j^2 = 1$ (a soma de todos os coeficientes do hiperplano deve ser 1).\n",
    "    - $y_i(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + ... + \\beta_px_{ip}) \\geq M(1-\\epsilon_i), \\forall i = 1,...,n$\n",
    "    - Com:  $\\epsilon_i \\geq 0$, $\\sum_{i=1}^n \\epsilon_i \\leq C$ \n",
    "\n",
    "OBS: $y_i \\in \\{-1,1\\}$\n",
    "\n",
    " $\\epsilon_i$ são **slack variables** que permitem que algumas observações caiam no lado errado da margem.\n",
    "- Se $\\epsilon_i = 0$: a observação está do lado correto da margem\n",
    "- Se $\\epsilon_i > 0$: a observação está do lado errado da margem\n",
    "- Se $\\epsilon_i > 1$: a observação está do lado errado do hiperplano\n",
    "\n",
    "O parâmetro C que controla a quantidade de violações do hiperplano permitidas.\n",
    "\n",
    "- Quanto maior é o valor de C, mais violações do hiperplano são permitidas (maior o bias)\n",
    "- Quanto menor é o valor de C, menos violações do hiperplano são permitidas (maior a variância).\n",
    "\n",
    "Podemos pensar no parâmetro C como sendo um custo. Se C = 10, então no máximo 10 pontos podem estar no lado errado do hiperplano ($\\epsilon_i > 1$). O parâmetro C é um tuning parameter, pode ser determinado com cross-validation.\n",
    "\n",
    "Veja o que acontece com o classificador conforme diminuímos o valor de C e ficamos mais exigentes com a quantidade de exemplos mal classificados:\n",
    "\n",
    "![svc_different_c_values](img/svc_different_c_values.png)\n",
    "\n",
    "Vantagens:\n",
    "- Maior robustez a exemplos individuais: No MMC, a adição de um exemplo podia deslocar muito o hiperplano e diminuir o poder de generalização:\n",
    "\n",
    "![outlier_mmc](img/outlier_mmc.png)\n",
    "\n",
    "No SVC, isso não acontece devido ao grau de tolerância definido a partir de C.\n",
    "\n",
    "### 7.3 Support Vector Machine\n",
    "\n",
    "Boa parte dos problemas tem uma decision boundary não linear:\n",
    "\n",
    "**Ideia:** **Aumentar o espaço dos preditores** incluindo variáveis “compostas” pode tornar a decision boundary não linear:\n",
    "\n",
    "- termos polinomiais (quadráticos, cúbicos, etc.). Por exemplo: $x_1^2, x_2^3, ...$.\n",
    "- termos de interação. Por exemplo: $x_1x_2, x_2x_3^3$.\n",
    "- outras funções\n",
    "\n",
    "No espaço aumentado, ainda se trata de um hiperplano e a decision boundary é linear. Entretanto, no espaço original, a decision boundary não é linear.\n",
    "\n",
    "Podemos escrever o SVC (seção anterior), como uma **soma de produtos internos**:\n",
    "\n",
    "$f(x) = \\beta_0 + \\sum_{i=1}^n \\alpha_i <x, x_i>$\n",
    "\n",
    "Os pontos que não são support vectors têm $\\alpha_i = 0$, somente aqueles que são support vectors contribuem pro modelo (chamaremos de conjunto $S$).\n",
    "\n",
    "$f(x) = \\beta_0 + \\sum_{i \\in S} \\alpha_i <x, x_i>$\n",
    "\n",
    "Para o SVM, nós queremos um comportamento não linear. Para isso, no lugar do produto interno $<x, x_i>$ nós utilizamos uma **kernel function**.\n",
    "\n",
    "Uma kernel function $K(x_i, x_j)$ tem o objetivo de dar uma estimativa de similaridade entre dois pontos de dados.\n",
    "\n",
    "Nosso modelo final fica: $f(x) = \\beta_0 + \\sum_{S} \\alpha_i K(x, x_i)$\n",
    "\n",
    "Ha diferentes tipos de kernel function que podemos utilizar:\n",
    "- Linear kernel: $K(x_i, x_j) = \\sum_{k=1}^p x_{ik}x_{jk}$ (equivale ao support vector classifier)\n",
    "- Polynomial kernel (de grau $d$): $K(x_i, x_j) = (1 + \\sum_{k=1}^p x_{ik}x_{jk})^d$, com $d > 0$\n",
    "- Radial kernel: $K(x_i, x_j) = exp(-\\gamma\\sum_{k=1}^p (x_{ik} - x_{jk})^2)$, com $\\gamma > 0$\n",
    "\n",
    "Por que kernels?\n",
    "- Reduz a quantidade de computação: só precisamos calcular o kernel para $\\binom{n}{2}$ pares distintos, devido às propriedades de **simetria** de um kernel function\n",
    "\t- também é conhecido como _Kernel Trick_: Na prática, as funções kernel apenas calculam as relações entre os pares de pontos **como se** eles estivessem em dimensões maiores, porém não realizam de fato essa transformação).\n",
    "\n",
    "#### Multiclasse\n",
    "\n",
    "Para classificar entre $K > 2$ classes, existem duas abordagens mais comuns:\n",
    "\n",
    "- One vs. One: construir um modelo para cada par de features: $\\binom{K}{2}$ modelos. Um novo exemplo $x*$ deve ser aplicado em todos os modelos e o atribuímos à classe para a qual o exemplo $x*$ foi mais atribuído.\n",
    "\n",
    "- One vs. all: construir vários modelos de uma classe contra todas as outras: $K$ modelos. ...\n",
    "\n",
    "#### Regressão Logística vs. SVM\n",
    "\n",
    "Regressão logística e SVM têm performances similares.\n",
    "\n",
    "Seja $p$ o número de features e $n$ o tamanho do training set\n",
    "- Se $p$ é **grande** em relação a $n$\n",
    "\t- Ex: problemas de classificação de textos\n",
    "\t\t- 10k features > 10-1k exemplos \n",
    "\t- Usar regressão logística ou SVM com kernel linear (SVC)\n",
    "- Se $p$ é **pequeno** e $n$ é **intermediário**\n",
    "\t- Ex: 1-1k features < 10-10k exemplos \n",
    "\t- Usar SVM com Gaussian Kernel\n",
    "- Se $p$ é **pequeno** e $n$ é **grande**\n",
    "\t- Ex: 1-1k features << 50k exemplos \n",
    "\t- SVM vai demorar para rodar com Gaussian Kernel\n",
    "    - Adicionar mais features OU\n",
    "    - Usar regressão logística ou SVM com kernel linear (SVC)\n",
    "\n",
    "OBS: SVM tem um problema de otimização convexo, e portanto, o mínimo obtido é **global**\n",
    "\n",
    "O problema de minimização que define o SVC pode ser reescrito como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{minimize}_{\\beta_0, \\beta_1, ... , \\beta_p}  \\left\\{ \\sum_{i=1}^n max[0,1-y_if(x_i)] + \\lambda\\sum_{j=1}^p \\beta_j^2 \\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "Onde $f(X) = \\beta_0 + \\beta_1X_1 + … + \\beta_pX_p$. \n",
    "\n",
    "Quando $\\lambda$ é grande:\n",
    "- $\\beta_1, …, \\beta_p$ são pequenos\n",
    "- Mais violações à margem são toleradas\n",
    "- Baixa variância\n",
    "- Alto bias\n",
    "\n",
    "Quando $\\lambda$ é pequeno:\n",
    "- $\\beta_1, …, \\beta_p$ são grandes\n",
    "- Menos violações à margem são toleradas\n",
    "- Alta variância\n",
    "- Baixo bias\n",
    "- $C$ é pequeno\n",
    "O termo $\\lambda\\sum_{j=1}^p \\beta_j^2$ corresponde ao termo de penalização ridge. \n",
    "\n",
    "Um ponto interessante é que no caso do SVC, a função de custo é exatamente zero para observações que estão do lado correto da margem. Já na regressão logística, esse valor não é exatamente zero, mas é bastante pequeno.\n",
    "\n",
    "Comparando-se as funções de custo, o SVM utiliza uma função _hinge loss_ (é **zero** para os exemplos que não são support vectors). Ao contrario, na regressão logística não é exatamente zero:\n",
    "\n",
    "![hinge_loss_log_loss](img/hinge_loss_log_loss.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
